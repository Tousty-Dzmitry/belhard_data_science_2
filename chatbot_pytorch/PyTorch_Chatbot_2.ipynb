{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiS2JUNwNx-I",
    "outputId": "f3198887-055a-4baf-a178-31db6d2a179c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Loss: 0.0032\n",
      "Epoch 400, Loss: 0.0010\n",
      "Epoch 600, Loss: 0.0005\n",
      "Epoch 800, Loss: 0.0003\n",
      "Epoch 1000, Loss: 0.0002\n",
      "Type 'exit' to quit.\n",
      "You: jjj\n",
      "Bot: hello\n",
      "You: bye\n",
      "Bot: goodbye\n",
      "You: exit\n",
      "Bot: goodbye\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Словарь\n",
    "vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"hello\": 3, \"hi\": 4, \"bye\": 5, \"goodbye\": 6}\n",
    "inv_vocab = {i: w for w, i in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 8\n",
    "hidden_size = 16\n",
    "max_len = 5\n",
    "\n",
    "# === Модель\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        _, h = self.rnn(x)\n",
    "        return h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embed(x)\n",
    "        out, h = self.rnn(x, h)\n",
    "        out = self.fc(out)\n",
    "        return out, h\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        h = self.encoder(src)\n",
    "        out, _ = self.decoder(tgt, h)\n",
    "        return out\n",
    "\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "# === Данные\n",
    "pairs = [\n",
    "    ([\"hello\"], [\"hi\"]),\n",
    "    ([\"hi\"], [\"hello\"]),\n",
    "    ([\"bye\"], [\"goodbye\"]),\n",
    "]\n",
    "\n",
    "def encode(sentence, vocab):\n",
    "    tokens = [vocab.get(w, vocab[\"<pad>\"]) for w in sentence] + [vocab[\"<eos>\"]]\n",
    "    tokens += [vocab[\"<pad>\"]] * (max_len - len(tokens))\n",
    "    return torch.tensor(tokens[:max_len])\n",
    "\n",
    "src_data = torch.stack([encode(src, vocab) for src, _ in pairs])\n",
    "tgt_data = torch.stack([encode([\"<sos>\"] + tgt, vocab) for _, tgt in pairs])\n",
    "tgt_labels = torch.stack([encode(tgt + [\"<eos>\"], vocab) for _, tgt in pairs])\n",
    "\n",
    "# === Обучение\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=vocab[\"<pad>\"])\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src_data.to(device), tgt_data.to(device))\n",
    "    loss = loss_fn(output.view(-1, vocab_size), tgt_labels.view(-1).to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# === Инференс\n",
    "def respond_to_input(input_word):\n",
    "    input_idx = vocab.get(input_word, vocab[\"<pad>\"])\n",
    "    src = torch.tensor([[input_idx, vocab[\"<eos>\"], 0, 0, 0]]).to(device)\n",
    "    h = model.encoder(src)\n",
    "    inputs = torch.tensor([[vocab[\"<sos>\"]]]).to(device)\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        out, h = model.decoder(inputs, h)\n",
    "        next_token = out.argmax(-1)[:, -1]\n",
    "        word = inv_vocab[next_token.item()]\n",
    "        if word == \"<eos>\":\n",
    "            break\n",
    "        output_sentence.append(word)\n",
    "        inputs = next_token.unsqueeze(0)\n",
    "\n",
    "    return \" \".join(output_sentence)\n",
    "\n",
    "# === Чат\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip().lower()\n",
    "        if user_input in {\"exit\", \"quit\"}:\n",
    "            print(\"Bot: goodbye\")\n",
    "            break\n",
    "        response = respond_to_input(user_input)\n",
    "        print(\"Bot:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
