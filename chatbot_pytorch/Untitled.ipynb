{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9007c1f-2c89-49da-9587-78c7eaae2869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/dzmitry/.pyenv/versions/3.10.0/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/dzmitry/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dzmitry/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dzmitry/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dzmitry/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/dzmitry/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e20a8b-2905-4b9f-8ba3-8d8e29cccdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf37f7b-c8d5-4e81-ba87-884ef804c5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e63196-82f0-43fd-a007-6605572a1cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чат-бот о уличной еде. Напишите название блюда, состав которого вы хотите узнать, или 'выход' для завершения.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  Hot Dog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бот: Это блюдо из: Sausage, Bun, Mustard, Ketchup\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Вы:  выход\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бот: До свидания! Приятного аппетита!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Загрузка словаря из файла ===\n",
    "def load_dictionary(file_path):\n",
    "    dictionary = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':' in line:\n",
    "                key, value = line.strip().split(':', 1)\n",
    "                dictionary[key.strip().lower()] = value.strip()\n",
    "    return dictionary\n",
    "\n",
    "# Загружаем словарь из файла\n",
    "food_dict = load_dictionary('global_street_food.txt')\n",
    "\n",
    "# === Создаем vocab на основе слов из словаря ===\n",
    "words = set()\n",
    "for key, value in food_dict.items():\n",
    "    words.update(key.split())\n",
    "    words.update(value.split())\n",
    "\n",
    "vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n",
    "for i, word in enumerate(words, start=3):\n",
    "    vocab[word] = i\n",
    "inv_vocab = {i: w for w, i in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 8\n",
    "hidden_size = 16\n",
    "max_len = 10  # Увеличили максимальную длину\n",
    "\n",
    "# === Модель (остается без изменений) ===\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        _, h = self.rnn(x)\n",
    "        return h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embed(x)\n",
    "        out, h = self.rnn(x, h)\n",
    "        out = self.fc(out)\n",
    "        return out, h\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        h = self.encoder(src)\n",
    "        out, _ = self.decoder(tgt, h)\n",
    "        return out\n",
    "\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "# === Генерация ответа ===\n",
    "def respond_to_input(user_input):\n",
    "    # Сначала проверяем точное совпадение в словаре\n",
    "    user_input_lower = user_input.lower()\n",
    "    if user_input_lower in food_dict:\n",
    "        return f\"Это блюдо из: {food_dict[user_input_lower]}\"\n",
    "    \n",
    "    # Если точного совпадения нет, используем модель\n",
    "    input_words = user_input_lower.split()\n",
    "    input_idx = [vocab.get(w, vocab[\"<pad>\"]) for w in input_words]\n",
    "    input_idx = input_idx[:max_len] + [vocab[\"<eos>\"]] + [vocab[\"<pad>\"]] * (max_len - len(input_words) - 1)\n",
    "    src = torch.tensor([input_idx[:max_len]]).to(device)\n",
    "    \n",
    "    h = model.encoder(src)\n",
    "    inputs = torch.tensor([[vocab[\"<sos>\"]]]).to(device)\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        out, h = model.decoder(inputs, h)\n",
    "        next_token = out.argmax(-1)[:, -1]\n",
    "        word = inv_vocab[next_token.item()]\n",
    "        if word == \"<eos>\":\n",
    "            break\n",
    "        output_sentence.append(word)\n",
    "        inputs = next_token.unsqueeze(0)\n",
    "\n",
    "    return \" \".join(output_sentence) if output_sentence else \"Я не знаю, что ответить.\"\n",
    "\n",
    "# === Чат-бот ===\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"Чат-бот о уличной еде. Напишите название блюда, состав которого вы хотите узнать, или 'выход' для завершения.\")\n",
    "    while True:\n",
    "        user_input = input(\"Вы: \").strip()\n",
    "        if user_input.lower() in {\"выход\", \"exit\", \"quit\"}:\n",
    "            print(\"Бот: До свидания! Приятного аппетита!\")\n",
    "            break\n",
    "        \n",
    "        response = respond_to_input(user_input)\n",
    "        print(\"Бот:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e399ab-fb33-4b72-abcf-b0ba69f89e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
